{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_theme('notebook')\n",
    "\n",
    "# models selection\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import fbeta_score, make_scorer, classification_report\n",
    "\n",
    "# pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# compose\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# preprocessings\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# features selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# resamplings\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "# algorithms\n",
    "## linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## svm\n",
    "from sklearn.svm import SVC\n",
    "## tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## ensample\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# others\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load Dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "df_base = pd.read_csv('../../../dataset/cleaned/train.csv')\n",
    "df_base['area_code'] = df_base['area_code'].astype(str)\n",
    "\n",
    "## \n",
    "num_cols = df_base.select_dtypes(np.number).columns.tolist()\n",
    "cat_cols = df_base.select_dtypes('object').columns.tolist()[0:-1]\n",
    "\n",
    "##\n",
    "num_idxes = [i for i, name in enumerate(df_base.columns.tolist()) if name in num_cols]\n",
    "cat_idxes = [i for i, name in enumerate(df_base.columns.tolist()) if name in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>User-Defined Functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsed names:\n",
    "def get_parsed_names(old_names: list, new_names: list) -> list:\n",
    "    parsed_names = []\n",
    "\n",
    "    for name in new_names:\n",
    "        eles = [ele for ele in re.split('_', name) if ele != '']\n",
    "        eles[1] = int(re.split('x', eles[1])[-1])\n",
    "\n",
    "        if name != 'remainder':\n",
    "            parsed_names.append(\n",
    "                f'{old_names[eles[1]]}_{eles[-1]}'\n",
    "            )\n",
    "        else:\n",
    "            parsed_names.append(f'{old_names[eles[1]]}')\n",
    "\n",
    "    return parsed_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "def get_train_test_split(df: pd.DataFrame) -> tuple[np.array: float, np.array: float, np.array: float, np.array: float, list]:\n",
    "    arr = df.copy().values\n",
    "    X, y =  arr[:, :-1], arr[:, -1]\n",
    "\n",
    "    ## le\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    ## ohe\n",
    "    ohe = [('ohe', OneHotEncoder(drop='first', sparse_output=False), cat_idxes)]\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=ohe, remainder='passthrough', \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    X = ct.fit_transform(X)\\\n",
    "        .astype(float)\n",
    "    \n",
    "    # parsed names\n",
    "    parsed_names = get_parsed_names(\n",
    "        old_names=df.columns.tolist(),\n",
    "        new_names=ct.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    ##\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, parsed_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, parsed_names = get_train_test_split(df=df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "def load_base_models() -> list:\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression(n_jobs=-1)))\n",
    "    models.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    models.append(('SVC', SVC()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('ET', ExtraTreesClassifier(n_jobs=-1)))\n",
    "    models.append(('RF', RandomForestClassifier(n_jobs=-1)))\n",
    "    models.append(('GB', GradientBoostingClassifier()))\n",
    "    models.append(('LGBM', LGBMClassifier(n_jobs=-1)))\n",
    "    models.append(('XGB', XGBClassifier(n_jobs=-1)))\n",
    "\n",
    "    return models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv result\n",
    "def get_kfold_result(models: list, X: np.array, y: np.array) -> tuple[np.array, np.array]:\n",
    "    ##\n",
    "    names, results = [], []\n",
    "    cv = RepeatedStratifiedKFold(\n",
    "        n_splits=10, n_repeats=3, \n",
    "        random_state=7\n",
    "    )\n",
    "    scoring = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    ##\n",
    "    for name, model in models:\n",
    "        cv_results = cross_val_score(\n",
    "            estimator=model, \n",
    "            X=X, y=y, \n",
    "            cv=cv, scoring=scoring, \n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f'{name}: {cv_results.mean()} ({cv_results.std()})')\n",
    "        names.append(name); results.append(cv_results)\n",
    "\n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>User-Defined Classes</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Standardization</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Power transformation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correspondence Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>PCA</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sequential feature selection</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>RFE</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Over sampling</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Combine</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
